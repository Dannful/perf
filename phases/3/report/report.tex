%%
%% This is file `sample-acmsmall.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,journal,bibtex,acmsmall')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-acmsmall.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[acmsmall]{acmart}
\usepackage{makecell}
\usepackage[brazil]{babel}
\usepackage{todonotes}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2025}
\acmYear{2025}

%%
%% These commands are for a JOURNAL article.
\acmJournal{JACM}
\acmVolume{37}
\acmNumber{4}
\acmArticle{111}
\acmMonth{11}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title[Análise: Fletcher]{Análise de uma aplicação de propagação de ondas sísmicas: Fletcher}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Francisco Pegoraro Etcheverria}
\author{Pedro Henrique Boniatti Colle}
\author{Vinícius Daniel Spadotto}
\affiliation{%
  \institution{Universidade Federal do Rio Grande do Sul}
  \city{Porto Alegre}
  \state{Rio Grande do Sul}
  \country{Brasil}
}

%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Etcheverria et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
  Este artigo apresenta uma análise de desempenho da aplicação Fletcher, focada na propagação de ondas sísmicas. O estudo avalia a escalabilidade e eficiência da aplicação em arquiteturas multi-core e aceleradores gráficos através de dois experimentos fatoriais. O primeiro experimento, com alta replicabilidade, validou o comportamento assintótico e a variância da aplicação. O segundo, focado em grandes volumes de dados, demonstrou a diluição do overhead de paralelismo. Os resultados confirmam a complexidade linear $O(n)$ e revelam que, embora a eficiência seja limitada em problemas pequenos devido a custos de sincronização, a aplicação atinge speedup quase linear e alta eficiência (>80\%) em cargas de trabalho intensivas, validando sua aptidão para Computação de Alto Desempenho (HPC).
\end{abstract}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Onda, Sísmica, Propagação, Perturbação, Fletcher}

\received{30 November 2025}
\received[revised]{30 November 2025}
\received[accepted]{30 November 2025}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
O objeto de estudo deste trabalho de análise de desempenho (INF01146/CMP223) é a aplicação Fletcher\footnote{Hospedada no repositório https://github.com/gabrielfrtg/fletcher-base}. Ela se baseia em \cite{FLETCHER}, que estabelece equações diferenciais para computar perturbações em meios inclinados transversalmente isótropos (TTI). A implementação escolhida também implementa os meios isotrópicos (ISO) e verticais transversalmente isótropos (VTI), que são simplificações nas equações da computação de meios TTI. As demais características de implementação e escolhas de design da aplicação estão contidas no seu manual\footnote{Fonte do pdf: https://drive.google.com/file/d/10CmbleCThUxZ9TUJ7gZkhwufPQZa3Nt4/view?usp=drive\_link}.

A aplicação é altamente paralelizável e este trabalho foca em determinar a sua escalabilidade vide a disponibilidade de recursos, assim como identificar \textit{bottle necks} presentes na computação. Utilizou-se diferentes \textit{backends} (CPU e GPU) para a computação, validando a escalabilidade individualmente em cada meio. Computações de meio misto, parte em CPU parte em GPU, ficam fora do escopo deste trabalho. A coleção e análise dos dados gerados destes experimentos busca servir como base para diferentes implementações do algoritmo Fletcher, aperfeiçoando aspectos da aplicação e estendendo suas capacidades, como uma implementação multi máquina usando MPI\cite{MPI}.

\section{Trabalhos relacionados}

A introdução já apresenta a pesquisa central no qual a aplicação Fletcher se baseia \cite{FLETCHER}. O modelo deste trabalho, análise de desempenho para diferentes parâmetros da aplicação, vai de encontro com a pesquisa de \citet{OPTIMIZEFLETCHER}. A pesquisa apresenta o desempenho da aplicação em diferentes arquiteturas (\textit{backends}), assim como otimizações para melhorá-lo em alguns desses contextos. Este trabalho serve como uma extensão dessa pesquisa, testando em arquiteturas mais modernas não presentes na época. 

As limitações da aplicação Fletcher já são conhecidas \cite{OPTIMIZEFLETCHER}. Trabalhos como 
\citet{IOFLETCH} e  \citet{MPIIOFLETCH} exploram formas de realizar IO para ler computações intermediárias da aplicação, sem causar grandes perdas de desempenho na aplicação. A análise do gasto energético e portabilidade da aplicação também foi estudado em \citet{ENERGYFLETCH}.

Ao analisar esses trabalhos, pode-se concluir que muito esforço já foi realizado partindo de uma análise já antiga da aplicação. Uma revisão dessa análise, usando arquiteturas mais modernas, é de alta relevância para trabalhos que o precederam e o sucederão.

\section{Metodologia}

A metodologia empregada para a realização do presente trabalho deu-se mediante a execução de experimentos com fatores pré-definidos e sob condições de execução estabelecidas e devidamente controladas para atingir os objetivos estipulados. Realizou-se inicialmente um projeto experimental que amplamente variava os fatores, com várias iterações, mas com um tempo de execução máximo pequeno. Isso permitiu explorar o espaço de possibilidades do projeto. Dessa primeira análise pode-se reduzir o escopo dos experimentos sem perder o foco do projeto, gerando um projeto experimental com execuções com um tempo máximo significativamente maior. Nessa segunda geração de resultado, consegui-se utilizar mais máquinas para observar os resultados para mais arquiteturas de GPU.

\subsection{Objetivos}

Este trabalho almeja gerar dados brutos, precisos e controlados que cubram todo o espaço de análise da aplicação. Com esses dados, busca-se analisar a correlação do tempo de execução e vasão de aplicações Fletcher com relação a tamanho de problema, número de iterações e arquitetura usada para computar. Dentre essas arquiteturas analisa-se o efeito do modelo de GPU e CPU nos parâmetros de saída analisados. Adicionalmente, no caso da CPU, considera-se também o número de \textit{threads} e o efeito destes na computação. A geração dessa análise busca apontar \textit{bottlenecks} no tempo de computação, assim como projetar tempos de execução para tamanhos maiores de problema. 

\subsection{Projetos experimentais}

Foram realizados \textbf{2} projetos experimentais \textit{full factorial} de múltiplos fatores em sequência. O primeiro buscou verificar se o incremento das iterações do problema era consequente a variância dos resultados. Com essa resposta em mãos, realizou-se o segundo projeto experimental, expandido o escopo para arquiteturas não compreendidas no primeiro projeto experimental. 

\begin{table}[H]
  \caption{Primeiro Projeto experimental}
  \label{tab:fstprojexp}
  \begin{tabular}{ccccc}
    \toprule
    \textit{Backend}&Dimensões do dado de entrada&N\textdegree de iterações&N\textdegree de \textit{threads}&Replicações\\
    \midrule
    CPU & $24^3$, $56^3$, $120^3$ & $10$, $100$, $1000$ & $1$, $2$, $4$, $8$, $16$ & 100\\
    GPU & $24^3$, $56^3$, $120^3$ & $10$, $100$, $1000$ & $-$ & 100\\
    \bottomrule
  \end{tabular}
\end{table}

\begin{table}[H]
  \caption{Segundo projetos experimental}
  \label{tab:sndprojexp}
  \begin{tabular}{ccccc}
    \toprule
    \textit{Backend}&Dimensões do dado de entrada&N\textdegree de iterações&N\textdegree de \textit{threads}&Replicações\\
    \midrule
    CPU & $24^3$, $88^3$, $152^3$, $248^3$, $376^3$, $504^3$ & $25$ & $1$, $2$, $4$, $8$, $16$ & 10\\
    GPU & $24^3$, $88^3$, $152^3$, $248^3$, $376^3$, $504^3$ & $25$ & $-$ & 10\\
    \bottomrule
  \end{tabular}
\end{table}

\subsection{Ambiente de execução}

Todos os experimentos foram executados no PCAD, https://gppd-hpc.inf.ufrgs.br, no INF/UFRGS, utilizando
as máquinas \textbf{draco} e \textbf{beagle}.

\begin{table}[H]
  \caption{Máquinas utilizadas para os experimentos}
  \label{tab:macexpcpu}
  \begin{tabular}{ccc}
    \toprule
    Projeto experimental&Experimento&Máquina\\
    \midrule
    1 & CPU & draco2\\
    1 & GPU & draco1\\
    2 & CPU & draco2\\
    2 & GPU & draco1\\
    2 & GPU & beagle\\
    \bottomrule
  \end{tabular}
\end{table}

\begin{table}[H]
  \caption{Especificações técnicas das máquinas utilizadas}
  \label{tab:macspec}
  \begin{tabular}{cccccc}
    \toprule
    Máquina&CPU&RAM&Acelerador&Disco\\
    \midrule
    draco[1,2] & \makecell{2 x Intel(R) Xeon(R) \\ E5-2640 v2, 2.00 GHz, \\ 32 threads, 16 cores} & 64 GB DDR3 & \makecell{NVIDIA Tesla K20m} & 1.8 TB HDD\\
    \hline
    beagle & \makecell{2 x Intel(R) Xeon(R) \\ E5-2650, 2.00 GHz, \\ 32 threads, 16 cores} & 32 GB DDR3 & \makecell{2 x NVIDIA GeForce GTX 1080 Ti} & 931 GB HDD\\
    \bottomrule
  \end{tabular}
\end{table}

\section{Resultados}

\subsection{Primeiro Projeto Experimental}
Realizou-se o primeiro projeto experimental \ref{tab:fstprojexp}. Nele, variou-se o tamanho do problema e o número de iterações, buscando realizar 100 replicações para cada caso. Mesmo reduzindo o tempo de execução de cada experimento usando tamanhos menores para o volume,  conseguiu-se apenas realizar 19 dessas replicações no tempo alocado para a computação. Entretanto, pôde-se observar que mesmo com esse número reduzido de replicações, nenhuma configuração do experimento apresentou variância significativa, independente do número de iterações.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{../analysis/plots/plot1a_execution_vs_total_exp1.pdf}
    \caption{Tempo de Execução vs. Tamanho Total: Experimento 1.}
    \label{fig:exec_time_exp1}
\end{figure}

Todas as computações também apresentam a mesma curva de crescimento independente do número de iterações para o programa. Ou seja, o crescimento do tempo de execução é consistente quanto ao número de iterações.

Uma característica do programa não antes discutida é a diferença entre tempo de computação, tempo realizando as contas propriamente; e tempo total. Esse tempo total inclui escrita em disco para salvar os resultados. Ele já pode ser notado na computação da GPU e será mais marcante no segundo projeto experimental. Isso também é ilustrado pelo tempo de \textit{overhead} (porcentagem do tempo total não focado em computação) observado. 

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{../analysis/plots/plot5a_overhead_percent_exp1.pdf}
    \caption{Tamanho do problema vs. Iterações vs. \textit{overhead}: Experimento 1.}
    \label{fig:overhead1}
\end{figure}

Observa-se que a GPU é tão veloz que a escrita em disco compreende parte significativa do tempo de execução, aumentando com o número de iterações e tamanho do problema. Isso é esperado. A cada iteração do programa, salva todo o volume em um arquivo, com uma estimativa de crescimento de $O(ti)$, com $t$ sendo o tamanho e $i$ sendo o número de iterações. A computação na CPU não parece ter essa escrita como um \textit{bottleneck} significativo, para maiores tamanhos, menos o tempo relativo.

Nisso, pode-se fixar o número de iterações visto que não há variância significativa. Utilizou-se 25 iterações como um meio-termo entre 10 e 100 iterações. Formulou-se então o projeto experimental \ref{tab:sndprojexp}.

\subsection{Segundo Projeto Experimental}
Realizou-se o segundo projeto experimental \ref{tab:sndprojexp} utilizando-se maiores tamanhos de problemas. Nisso, replica-se o gráfico \ref{fig:exec_time_exp1}, agora com iterações fixas em 25 e com mais uma arquitetura de GPU.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{../analysis/plots/plot1b_execution_vs_total_exp2.pdf}
    \caption{Tamanho do Problema vs. Tempo de execução: experimento 2.}
    \label{fig:exec2}
\end{figure}

A escalabilidade do problema se apresenta igual. Quanto maior o problema, maior demora no tempo de execução. Observa-se que não se conseguiu executar para o tamanho $= 500$ na GPU da \textit{draco}, pois esta não tinha memória suficiente para conter o volume inteiro. Ao observar então as \textit{Msamples/s} do programa, constrói-se o gráfico \ref{fig:throughput2}, que demonstra o crescimento da eficiência de computação de cada arquitetura a medida que o programa cresce. A \textit{beagle} mostrou um crescimento significativo, porém com uma variância grande, até o tamanho de $150^3$. Depois desse ponto, a saturação dos recursos computacionais da GPU ocasionou a atenuação de throughput observada no gráfico \ref{fig:throughput2}.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{../analysis/plots/plot2b_throughput_exp2.pdf}
    \caption{Tamanho do problema vs. Iterações vs. Throughput: Experimento 2.}
    \label{fig:throughput2}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{../analysis/plots/plot5b_overhead_percent_exp2.pdf}
    \caption{Tamanho do problema vs. Iterações vs. \textit{overhead}: Experimento 2.}
    \label{fig:overhead2}
\end{figure}

No lado da CPU, pode-se desenhar um gráfico de gnanho de eficiência, no qual o eixo y contém o \textit{speedup} (ganho de velocidade) relativo a uma \textit{thread}. No Gráfico \ref{fig:speedup2}, observa-se que o ganho de velocidade com o aumento de \textit{thread} é quase que totalmente linear, com o tempo total caindo sempre abaixo dessa linha. 

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{../analysis/plots/plot3b_cpu_speedup_exp2.pdf}
    \caption{Número de \textit{threads} vs. \textit{speedup}: Experimento 2.}
    \label{fig:speedup2}
\end{figure}

\section{Conclusão}

A análise de desempenho conduzida sobre a aplicação Fletcher permitiu uma caracterização detalhada de seu comportamento em diferentes escalas de processamento. Os experimentos confirmaram rigorosamente a complexidade linear $O(n)$ do algoritmo, demonstrando estabilidade e previsibilidade tanto em CPU quanto em GPU.

A distinção entre os dois projetos experimentais foi crucial para identificar os limites da implementação. Enquanto o primeiro experimento evidenciou o impacto significativo do \textit{overhead} de gerenciamento de threads em volumes de dados menores, o segundo comprovou a excelente escalabilidade da aplicação quando submetida a cargas de trabalho adequadas. A capacidade de manter a eficiência acima de 80\% com 16 threads em grandes problemas indica que a aplicação é "fracamente escalável" e se beneficia diretamente do aumento da granularidade da tarefa.

Assim como reconhecido por \citet{IOFLETCH}, um grande \textit{bottleneck} da aplicação, principalmente quando usado GPUs, é o IO. Sendo o significativo elemento a restringir a capacidade de computação das GPU quanto a maiores volumes. Outro aspecto, observável é que a linearidade segue a quantidade de memória da GPU. Portanto, para maiores problemas, neste contexto \textit{single-core}, é necessário placas de vídeo com mais memória para executar na projeção desenhada.

A aplicação Fletcher é uma aplicação altamente escalável, sendo a mais eficiente quando usando GPU, mesmo com o \textit{bottleneck} de IO. Com isso, ela tem muitos ângulos para crescer e se desenvolver, expandindo para arquiteturas mistas, multi-core, etc.

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{report}

\end{document}
\endinput

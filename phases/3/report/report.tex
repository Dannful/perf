%%
%% This is file `sample-acmsmall.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `all,journal,bibtex,acmsmall')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-acmsmall.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%%
%% Commands for TeXCount
%TC:macro \cite [option:text,text]
%TC:macro \citep [option:text,text]
%TC:macro \citet [option:text,text]
%TC:envir table 0 1
%TC:envir table* 0 1
%TC:envir tabular [ignore] word
%TC:envir displaymath 0 word
%TC:envir math 0 word
%TC:envir comment 0 0
%%
%% The first command in your LaTeX source must be the \documentclass
%% command.
%%
%% For submission and review of your manuscript please change the
%% command to \documentclass[manuscript, screen, review]{acmart}.
%%
%% When submitting camera ready or to TAPS, please change the command
%% to \documentclass[sigconf]{acmart} or whichever template is required
%% for your publication.
%%
%%
\documentclass[acmsmall]{acmart}
\usepackage{makecell}
\usepackage[brazil]{babel}
%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    Bib\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmlicensed}
\copyrightyear{2025}
\acmYear{2025}

%%
%% These commands are for a JOURNAL article.
\acmJournal{JACM}
\acmVolume{37}
\acmNumber{4}
\acmArticle{111}
\acmMonth{11}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% For managing citations, it is recommended to use bibliography
%% files in BibTeX format.
%%
%% You can then either use BibTeX with the ACM-Reference-Format style,
%% or BibLaTeX with the acmnumeric or acmauthoryear sytles, that include
%% support for advanced citation of software artefact from the
%% biblatex-software package, also separately available on CTAN.
%%
%% Look at the sample-*-biblatex.tex files for templates showcasing
%% the biblatex styles.
%%

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title[Análise: Fletcher]{Análise de uma aplicação de propagação de ondas sísmicas: Fletcher}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.
\author{Francisco Pegoraro Etcheverria}
\author{Pedro Henrique Boniatti Colle}
\author{Vinícius Daniel Spadotto}
\affiliation{%
  \institution{Universidade Federal do Rio Grande do Sul}
  \city{Porto Alegre}
  \state{Rio Grande do Sul}
  \country{Brasil}
}

%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
\renewcommand{\shortauthors}{Etcheverria et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
  Este artigo apresenta uma análise de desempenho da aplicação Fletcher, focada na propagação de ondas sísmicas. O estudo avalia a escalabilidade e eficiência da aplicação em arquiteturas multi-core e aceleradores gráficos através de dois experimentos fatoriais. O primeiro experimento, com alta replicabilidade, validou o comportamento assintótico e a variância da aplicação. O segundo, focado em grandes volumes de dados, demonstrou a diluição do overhead de paralelismo. Os resultados confirmam a complexidade linear $O(n)$ e revelam que, embora a eficiência seja limitada em problemas pequenos devido a custos de sincronização, a aplicação atinge speedup quase linear e alta eficiência (>80\%) em cargas de trabalho intensivas, validando sua aptidão para Computação de Alto Desempenho (HPC).
\end{abstract}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{Onda, Sísmica, Propagação, Perturbação, Fletcher}

\received{30 November 2025}
\received[revised]{30 November 2025}
\received[accepted]{30 November 2025}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
O objeto de estudo deste trabalho de análise de desempenho (INF01146/CMP223) é a aplicação Fletcher\footnote{Hospedada no repositório https://github.com/gabrielfrtg/fletcher-base}. Ela se baseia em \cite{FLETCHER}, que estabelece equações diferenciais para computar perturbações em meios inclinados transversalmente isótropos (TTI). A implementação escolhida também implementa os meios isotrópicos (ISO) e verticais transversalmente isótropos (VTI), que são simplificações nas equações da computação de meios TTI. As demais características de implementação e escolhas de design da aplicação estão contidas no seu manual\footnote{Fonte do pdf: https://drive.google.com/file/d/10CmbleCThUxZ9TUJ7gZkhwufPQZa3Nt4/view?usp=drive\_link}.

A aplicação é altamente paralelizável e este trabalho foca em determinar a sua escalabilidade vide a disponibilidade de recursos, assim como identificar \textit{bottle necks} presentes na computação. Utilizou-se diferentes \textit{backends} (CPU e GPU) para a computação, validando a escalabilidade individualmente em cada meio. Computações de meio misto, parte em CPU parte em GPU, ficam fora do escopo deste trabalho. A coleção e análise dos dados gerados destes experimentos busca servir como base para diferentes implementações do algoritmo Fletcher, aperfeiçoando aspectos da aplicação e estendendo suas capacidades, como uma implementação multi máquina usando MPI\cite{MPI}.

\section{Trabalhos relacionados}

A introdução já apresenta a pesquisa central no qual a aplicação Fletcher se baseia \cite{FLETCHER}. O modelo deste trabalho, de analise de desempenho para diferentes parâmetros da aplicação, vai de encontro com a pesquisa de \citet{OPTIMIZEFLETCHER}. A pesquisa apresenta a performance da aplicação em diferentes arquiteturas (\textit{backends}), assim como otimizações para melhor a performance da aplicação quanto a essas. Este trabalho serve como uma extensão dessa pesquisa, testando em arquiteturas mais modernas não presentes na época. 

As limitações da aplicação Fletcher já são conhecidas \cite{OPTIMIZEFLETCHER}. Trabalhos como 
\citet{IOFLETCH} e  \citet{MPIIOFLETCH} exploram formas de realizar IO para ler computações intermediárias da aplicação, sem causar grandes perdas de performance na aplicação. A análise do gasto energético e portabilidade da aplicação também foi estudado em \citet{ENERGYFLETCH}.

A conclusão desses trabalhos é que muito esforço já foi realizado partindo de uma análise já antiga da aplicação. Uma revisão dessa análise, usando arquiteturas mais modernas, é de alta relevância para os trabalhos que precederam e sucederão.

\section{Metodologia}

A metodologia empregada para a realização do presente trabalho deu-se mediante
a execução de experimentos com fatores pré-definidos e sob condições de execução estabelecidas e
devidamente controladas para atingir os objetivos estipulados.

\subsection{Objetivos}

Visou-se a configurar um ambiente suficientemente controlado para a observação do comportamento da aplicação,
focando em como os fatores definidos para a execução impactam nas saídas capturadas. Definiu-se, pois, como objetivo a
obtenção dos dados brutos e a subsequente utilização destes para a construção de um modelo de regressão linear que apropriadamente
relacionasse os fatores à saída---esta dada em \textit{MSamples/s}---devidamente fundamentada por um teste de hipótese adequado.

\subsection{Projetos experimentais}

Foram realizados \textbf{2} projetos experimentais \textit{full factorial} de múltiplos fatores em sequência, tendo o último sido baseado nas observações
advindas da execucação do primeiro.

Cada projeto foi dividido em dois conjuntos de experimentos distintos: \textbf{CPU} e \textbf{GPU}.

\begin{table}[H]
  \caption{Projetos experimentais para CPU}
  \label{tab:projexpcpu}
  \begin{tabular}{ccccc}
    \toprule
    Projeto experimental&Dimensões do dado de entrada&N\textdegree de iterações&N\textdegree de \textit{threads}&Replicações\\
    \midrule
    1 & $24^3$, $56^3$, $120^3$ & $10$, $100$, $1000$ & $1$, $2$, $4$, $8$, $16$ & 100\\
    2 & $24^3$, $88^3$, $152^3$, $248^3$, $376^3$, $504^3$ & $25$ & $1$, $2$, $4$, $8$, $16$ & 10\\
    \bottomrule
  \end{tabular}
\end{table}

\begin{table}[H]
  \caption{Projetos experimentais para GPU}
  \label{tab:projexpgpu}
  \begin{tabular}{cccc}
    \toprule
    Projeto experimental&Dimensões do dado de entrada&N\textdegree de iterações&Replicações\\
    \midrule
    1 & $24^3$, $56^3$, $120^3$ & $10$, $100$, $1000$ & 100\\
    2 & $24^3$, $88^3$, $152^3$, $248^3$, $376^3$, $504^3$ & $25$ & 10\\
    \bottomrule
  \end{tabular}
\end{table}

\subsection{Ambiente de execução}

Todos os experimentos foram executados no PCAD, https://gppd-hpc.inf.ufrgs.br, no INF/UFRGS, utilizando
as máquinas \textbf{draco} e \textbf{beagle}.

\begin{table}[H]
  \caption{Máquinas utilizadas para os experimentos}
  \label{tab:macexpcpu}
  \begin{tabular}{ccc}
    \toprule
    Projeto experimental&Experimento&Máquina\\
    \midrule
    1 & CPU & draco2\\
    1 & GPU & draco1\\
    2 & CPU & draco2\\
    2 & GPU & draco1\\
    2 & GPU & beagle\\
    \bottomrule
  \end{tabular}
\end{table}

\begin{table}[H]
  \caption{Especificações técnicas das máquinas utilizadas}
  \label{tab:macspec}
  \begin{tabular}{cccccc}
    \toprule
    Máquina&CPU&RAM&Acelerador&Disco\\
    \midrule
    draco[1,2] & \makecell{2 x Intel(R) Xeon(R) \\ E5-2640 v2, 2.00 GHz, \\ 32 threads, 16 cores} & 64 GB DDR3 & \makecell{NVIDIA Tesla K20m} & 1.8 TB HDD\\
    \hline
    beagle & \makecell{2 x Intel(R) Xeon(R) \\ E5-2650, 2.00 GHz, \\ 32 threads, 16 cores} & 32 GB DDR3 & \makecell{2 x NVIDIA GeForce GTX 1080 Ti} & 931 GB HDD\\
    \bottomrule
  \end{tabular}
\end{table}

\section{Resultados}

Após a execução do primeiro projeto experimental, observou-se a possibilidade de realizar um novo projeto,
almejando um tamanho de problema de entrada maior, porém com uma quantidade menor de iterações. Conforme
as tabelas \ref{tab:projexpcpu} e \ref{tab:projexpgpu}, a primeira bateria experimental confere uma variabilidade menor
às observações, em virtude da maior quantidade de replicações para cada execução. Entretanto, a maior diversidade de tamanho
de problema de entrada permite a identificação mais precisa da influência de tal fator na métrica de saída (\textit{MSamples/s}).

Os projetos experimentais supracitados permitiram a obtenção de um $R^2 \approx 0.9898$ para os experimentos de \textbf{CPU} e um
$R^2 \approx 0.68$ para \textbf{GPU}.

Embora a métrica $R^2$ para CPU seja satisfatória, o modelo revelou que o fator de maior contribuição para a métrica de saída é o
\textbf{número de threads}, sendo a razão para tal imediata: a complexidade de cálculo associada ao tamanho do problema manteve-se
similar em sua ordem de grandeza, implicando a situação supracitada, porquanto a aplicação comporta-se conforme $O(n)$ em relação às dimensões do dado
de entrada. A quantidade de iterações, por sua vez, embora tenha variado razoavelmente em sua magnitude, depende intrinsicamente da complexidade de cálculo
associada, levando, pois, à sua tênue contribuição para os valores observados.

Outrossim, o $R^2$ calculado para a GPU é esperado: dado que a complexidade de cálculo torna-se substancialmente menor em virtude da maior exploração
do paralelismo, o modelo de regressão dispõe de informações altamente limitadas para determinar como cada fator influencia a saída. Dessa forma, todos os fatores
acabam por contribuir de maneira similarmente igual e tênue para os valores de saída, conferindo elevada incerteza para o modelo.

A seguir, discutem-se os detalhes de cada etapa experimental, integrando as análises visuais à narrativa de desempenho da aplicação.

\subsection{Experimento 1: Comportamento Assintótico e Variância}

O foco inicial desta etapa foi validar o comportamento do algoritmo sob condições estatisticamente robustas (100 replicações), utilizando tamanhos de problema contidos ($24^3$ a $120^3$).

A Figura \ref{fig:exec_time_exp1} corrobora a complexidade $O(n)$ da aplicação. A linearidade observada é rigorosa, e as barras de erro (ínfimas devido à alta replicabilidade) confirmam a estabilidade da implementação no ambiente de testes. O tempo de execução cresce de maneira previsível, sem desvios que indiquem anomalias no algoritmo.

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=\textwidth]{../analysis/plots/plot1a_execution_vs_total_exp1.pdf}
    \caption{Tempo de Execução vs. Tamanho Total: Experimento 1. A linearidade confirma a complexidade $O(n)$.}
    \label{fig:exec_time_exp1}
\end{figure}

No entanto, a utilização de tamanhos de problema menores revela o custo relativo da gestão de paralelismo. Conforme observado na Figura \ref{fig:overhead_exp1}, a sobrecarga (overhead) percentual é significativamente alta para entradas pequenas. Nestes cenários, a granularidade da tarefa é fina demais, fazendo com que o tempo gasto criando e sincronizando \textit{threads} represente uma fração substancial do tempo total.

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=\textwidth]{../analysis/plots/plot5a_overhead_percent_exp1.pdf}
    \caption{Sobrecarga Percentual: Experimento 1. O impacto da gestão de threads é acentuado em cargas menores.}
    \label{fig:overhead_exp1}
\end{figure}

Este overhead impõe um teto ao ganho de desempenho. A Figura \ref{fig:speedup_exp1} demonstra que o Speedup se distancia do ideal linear à medida que o número de threads aumenta. Para os menores problemas ($24^3$), o ganho de velocidade estagna rapidamente, pois o custo de comunicação anula os benefícios de adicionar mais unidades de processamento.

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=\textwidth]{../analysis/plots/plot3a_cpu_speedup_exp1.pdf}
    \caption{Speedup em CPU: Experimento 1. Saturação precoce do ganho de velocidade em problemas pequenos.}
    \label{fig:speedup_exp1}
\end{figure}

Consequentemente, a eficiência paralela sofre uma degradação acentuada. A Figura \ref{fig:efficiency_exp1} ilustra como a eficiência cai drasticamente para problemas pequenos ao utilizar muitas threads. Isso evidencia que, para esta escala de dados, a aplicação é subutilizada em arquiteturas com muitos núcleos.

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=\textwidth]{../analysis/plots/plot4a_cpu_efficiency_exp1.pdf}
    \caption{Eficiência em CPU: Experimento 1. Queda de eficiência devido à Lei de Amdahl e overhead fixo.}
    \label{fig:efficiency_exp1}
\end{figure}

A métrica final de desempenho bruto, a vazão (throughput), é apresentada na Figura \ref{fig:throughput_exp1}. Observa-se que, embora a vazão aumente com o tamanho do problema, ela tende a estabilizar, sugerindo que gargalos de memória ou overheads de sistema impedem um crescimento contínuo nesta escala de teste.

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=\textwidth]{../analysis/plots/plot2a_throughput_exp1.pdf}
    \caption{Vazão (MSamples/s): Experimento 1. Estabilização do throughput.}
    \label{fig:throughput_exp1}
\end{figure}

\subsection{Experimento 2: Escalabilidade em Larga Escala}

Com base na estabilidade verificada anteriormente, o Experimento 2 estressou a arquitetura com volumes de dados significativamente maiores (até $504^3$). A Figura \ref{fig:exec_time_exp2} demonstra que, mesmo sob carga intensa e com menos replicações, a aplicação mantém seu comportamento linear previsível, sem apresentar degradação de performance por \textit{thrashing} de cache ou memória virtual.

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=\textwidth]{../analysis/plots/plot1b_execution_vs_total_exp2.pdf}
    \caption{Tempo de Execução vs. Tamanho Total: Experimento 2. Linearidade mantida em escalas maiores.}
    \label{fig:exec_time_exp2}
\end{figure}

O principal benefício do aumento da carga de trabalho é a diluição dos custos fixos de paralelismo. Ao comparar a Figura \ref{fig:overhead_exp2} com o experimento anterior, nota-se uma queda drástica na sobrecarga percentual. O tempo de computação útil domina a execução, tornando o custo de gerenciamento de threads virtualmente negligenciável para os maiores problemas.

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=\textwidth]{../analysis/plots/plot5b_overhead_percent_exp2.pdf}
    \caption{Sobrecarga Percentual: Experimento 2. Diluição significativa do overhead.}
    \label{fig:overhead_exp2}
\end{figure}

Com o overhead controlado, a escalabilidade da aplicação melhora substancialmente. A Figura \ref{fig:speedup_exp2} mostra curvas de Speedup muito mais próximas do ideal linear, indicando que a adição de recursos computacionais está sendo efetivamente convertida em desempenho.

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=\textwidth]{../analysis/plots/plot3b_cpu_speedup_exp2.pdf}
    \caption{Speedup em CPU: Experimento 2. Escalabilidade superior devido à maior granularidade.}
    \label{fig:speedup_exp2}
\end{figure}

Da mesma forma, a eficiência paralela é preservada. A Figura \ref{fig:efficiency_exp2} evidencia que, para grandes volumes de dados, a eficiência permanece elevada (acima de 80\% em muitos casos) mesmo com 16 threads. Isso confirma que a aplicação Fletcher é "fracamente escalável" (weak scaling), beneficiando-se do aumento do tamanho do problema proporcionalmente aos recursos.

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=\textwidth]{../analysis/plots/plot4b_cpu_efficiency_exp2.pdf}
    \caption{Eficiência em CPU: Experimento 2. Alta eficiência mantida em cargas elevadas.}
    \label{fig:efficiency_exp2}
\end{figure}

Por fim, a vazão atinge seus valores máximos no Experimento 2. A Figura \ref{fig:throughput_exp2} mostra que, ao alimentar a CPU com dados suficientes para saturar as unidades de ponto flutuante e mascarar latências de memória, a aplicação atinge um patamar de performance significativamente superior ao observado no primeiro experimento.

\begin{figure}[hbt!]
    \centering
    \includegraphics[width=\textwidth]{../analysis/plots/plot2b_throughput_exp2.pdf}
    \caption{Vazão (MSamples/s): Experimento 2. Máximo desempenho obtido com saturação de recursos.}
    \label{fig:throughput_exp2}
\end{figure}

\section{Conclusão}

A análise de desempenho conduzida sobre a aplicação Fletcher permitiu uma caracterização detalhada de seu comportamento em diferentes escalas de processamento. Os experimentos confirmaram rigorosamente a complexidade linear $O(n)$ do algoritmo, demonstrando estabilidade e previsibilidade tanto em CPU quanto em GPU.

A distinção entre os dois projetos experimentais foi crucial para identificar os limites da implementação. Enquanto o primeiro experimento evidenciou o impacto significativo do overhead de gerenciamento de threads em volumes de dados menores, o segundo comprovou a excelente escalabilidade da aplicação quando submetida a cargas de trabalho adequadas. A capacidade de manter a eficiência acima de 80\% com 16 threads em grandes problemas indica que a aplicação é "fracamente escalável" e se beneficia diretamente do aumento da granularidade da tarefa.

Conclui-se que a aplicação Fletcher está bem otimizada para execução intra-nó em arquiteturas modernas. Os resultados obtidos fornecem uma base sólida para o desenvolvimento futuro de uma versão distribuída utilizando MPI, visto que o gargalo de computação local foi minimizado e o comportamento da aplicação é agora bem compreendido.

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{report}

\end{document}
\endinput
